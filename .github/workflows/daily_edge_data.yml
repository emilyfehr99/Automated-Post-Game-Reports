name: Daily NHL Edge Data Scraping

on:
  schedule:
    # Run every day at 6:00 AM Central Time (12:00 PM UTC)
    - cron: '0 12 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-edge-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas
        
    - name: Scrape NHL Edge Data
      run: |
        echo "ğŸ’ Starting daily NHL Edge data scraping..."
        python3 daily_edge_data_scraper.py
        
    - name: Check if data was scraped successfully
      run: |
        if [ -f "nhl_edge_data.json" ]; then
          echo "âœ… Edge data file created successfully"
          echo "ğŸ“Š File size: $(wc -c < nhl_edge_data.json) bytes"
          echo "ğŸ“… Last modified: $(stat -c %y nhl_edge_data.json)"
        else
          echo "âŒ Edge data file not found"
          exit 1
        fi
        
    - name: Commit and push Edge data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add nhl_edge_data.json
        git diff --staged --quiet || git commit -m "Update NHL Edge data - $(date '+%Y-%m-%d')"
        git push
        
    - name: Send success notification
      if: success()
      run: |
        echo "ğŸ‰ Daily NHL Edge data scraping completed successfully!"
        echo "ğŸ“Š Fresh Edge data ready for daily predictions"
        echo "â° Next predictions will include updated speed/distance metrics"
        
    - name: Send failure notification
      if: failure()
      run: |
        echo "âŒ Daily NHL Edge data scraping failed!"
        echo "âš ï¸ Predictions will use cached data or default values"
